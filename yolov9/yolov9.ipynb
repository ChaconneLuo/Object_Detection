{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxWxpz4-gAH6","outputId":"7d67fa13-d40e-4d09-8d81-49aae9e0bed5","execution":{"iopub.status.busy":"2024-05-13T19:00:14.324425Z","iopub.execute_input":"2024-05-13T19:00:14.324819Z","iopub.status.idle":"2024-05-13T19:00:15.361332Z","shell.execute_reply.started":"2024-05-13T19:00:14.324781Z","shell.execute_reply":"2024-05-13T19:00:15.360215Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Mon May 13 19:00:15 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   46C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   44C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I3YMj--ygAH8","outputId":"70c60099-0a4f-4bf0-9036-20681f36a910","execution":{"iopub.status.busy":"2024-05-13T19:00:41.411926Z","iopub.execute_input":"2024-05-13T19:00:41.412794Z","iopub.status.idle":"2024-05-13T19:00:41.417299Z","shell.execute_reply.started":"2024-05-13T19:00:41.412758Z","shell.execute_reply":"2024-05-13T19:00:41.416403Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/WongKinYiu/yolov9.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNYuFbmDgAH8","outputId":"1e3fc520-c8d1-4a13-d7ca-f47be875d7d5","execution":{"iopub.status.busy":"2024-05-13T19:00:53.634570Z","iopub.execute_input":"2024-05-13T19:00:53.634915Z","iopub.status.idle":"2024-05-13T19:00:55.351065Z","shell.execute_reply.started":"2024-05-13T19:00:53.634880Z","shell.execute_reply":"2024-05-13T19:00:55.350162Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Cloning into 'yolov9'...\nremote: Enumerating objects: 668, done.\u001b[K\nremote: Counting objects: 100% (290/290), done.\u001b[K\nremote: Compressing objects: 100% (91/91), done.\u001b[K\nremote: Total 668 (delta 222), reused 199 (delta 199), pack-reused 378\u001b[K\nReceiving objects: 100% (668/668), 3.22 MiB | 17.65 MiB/s, done.\nResolving deltas: 100% (269/269), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd yolov9\n!pip3 install -r requirements.txt -q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_M1lmDMgAH8","outputId":"40964fe5-6074-4673-8243-037630dd2f85","execution":{"iopub.status.busy":"2024-05-13T19:00:58.050932Z","iopub.execute_input":"2024-05-13T19:00:58.051303Z","iopub.status.idle":"2024-05-13T19:01:12.745438Z","shell.execute_reply.started":"2024-05-13T19:00:58.051271Z","shell.execute_reply":"2024-05-13T19:01:12.744462Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov9\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install -q roboflow","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qEvXv9l_gAH8","outputId":"19b5d82e-4ff5-4a86-b3cc-b1ea53d81f8c","execution":{"iopub.status.busy":"2024-05-13T19:01:30.439159Z","iopub.execute_input":"2024-05-13T19:01:30.439545Z","iopub.status.idle":"2024-05-13T19:01:42.594111Z","shell.execute_reply.started":"2024-05-13T19:01:30.439506Z","shell.execute_reply":"2024-05-13T19:01:42.593046Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt","metadata":{"id":"zvU8yIN4gAH8","execution":{"iopub.status.busy":"2024-05-13T19:01:59.672109Z","iopub.execute_input":"2024-05-13T19:01:59.672465Z","iopub.status.idle":"2024-05-13T19:02:06.189516Z","shell.execute_reply.started":"2024-05-13T19:01:59.672436Z","shell.execute_reply":"2024-05-13T19:02:06.188272Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!ls -la {HOME}/weights","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9XIcVbHagAH9","outputId":"f6b95fc8-50df-4810-bc20-09c4a37c5335","execution":{"iopub.status.busy":"2024-05-13T19:02:41.016205Z","iopub.execute_input":"2024-05-13T19:02:41.016581Z","iopub.status.idle":"2024-05-13T19:02:41.963431Z","shell.execute_reply.started":"2024-05-13T19:02:41.016546Z","shell.execute_reply":"2024-05-13T19:02:41.962334Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"total 402444\ndrwxr-xr-x 2 root root      4096 May 13 19:02 .\ndrwxr-xr-x 5 root root      4096 May 13 19:02 ..\n-rw-r--r-- 1 root root  51508261 Feb 18 12:36 gelan-c.pt\n-rw-r--r-- 1 root root 117203713 Feb 18 12:36 gelan-e.pt\n-rw-r--r-- 1 root root 103153312 Feb 18 12:36 yolov9-c.pt\n-rw-r--r-- 1 root root 140217688 Feb 18 12:36 yolov9-e.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd {HOME}/yolov9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kbXhnTmgAH9","outputId":"43b9914a-e090-4379-93a5-edc2a95b3235","execution":{"iopub.status.busy":"2024-05-13T19:02:45.086645Z","iopub.execute_input":"2024-05-13T19:02:45.087332Z","iopub.status.idle":"2024-05-13T19:02:45.093578Z","shell.execute_reply.started":"2024-05-13T19:02:45.087295Z","shell.execute_reply":"2024-05-13T19:02:45.092711Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov9\n","output_type":"stream"}]},{"cell_type":"code","source":"from roboflow import Roboflow\nrf = Roboflow(api_key=\"1gBpoxVirzj0NHBuskuN\")\nproject = rf.workspace(\"xy-z\").project(\"fire-0lzg9\")\nversion = project.version(2)\ndataset = version.download(\"yolov9\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50Yh7sebgAH9","outputId":"47d969ff-c5a1-4337-ff27-5cabd93c2c6f","execution":{"iopub.status.busy":"2024-05-13T19:02:48.381281Z","iopub.execute_input":"2024-05-13T19:02:48.381975Z","iopub.status.idle":"2024-05-13T19:03:18.976599Z","shell.execute_reply.started":"2024-05-13T19:02:48.381938Z","shell.execute_reply":"2024-05-13T19:03:18.975861Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"loading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in fire-2 to yolov9:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 945842/945842 [00:23<00:00, 39748.52it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to fire-2 in yolov9:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32168/32168 [00:04<00:00, 7051.75it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"%cd {HOME}/yolov9\n\n!python train.py \\\n--batch 128 --epochs 24 --img 640 --device 0,1 --min-items 0 --close-mosaic 15 \\\n--data {dataset.location}/data.yaml \\\n--weights {HOME}/weights/gelan-c.pt \\\n--cfg models/detect/gelan-c.yaml \\\n--hyp hyp.scratch-high.yaml","metadata":{"execution":{"iopub.status.busy":"2024-05-13T19:09:27.090073Z","iopub.execute_input":"2024-05-13T19:09:27.090884Z","iopub.status.idle":"2024-05-13T19:10:30.282753Z","shell.execute_reply.started":"2024-05-13T19:09:27.090845Z","shell.execute_reply":"2024-05-13T19:10:30.281756Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov9\n2024-05-13 19:09:33.834924: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-13 19:09:33.834985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-13 19:09:33.836409: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=/kaggle/working/weights/gelan-c.pt, cfg=models/detect/gelan-c.yaml, data=/kaggle/working/yolov9/fire-2/data.yaml, hyp=hyp.scratch-high.yaml, epochs=24, batch_size=128, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0,1, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\nYOLO ðŸš€ v0.1-89-g93f1a28 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n                                                    CUDA:1 (Tesla T4, 15102MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ðŸš€ in ClearML\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ðŸš€ runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=11\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n 22      [15, 18, 21]  1   5499121  models.yolo.DDetect                     [11, [256, 512, 512]]         \ngelan-c summary: 621 layers, 25445553 parameters, 25445537 gradients, 103.2 GFLOPs\n\nTransferred 931/937 items from /kaggle/working/weights/gelan-c.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.001), 160 bias\nWARNING âš ï¸ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov9/fire-2/train/labels.cache... 14517 images\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov9/fire-2/valid/labels.cache... 1038 images, 0\u001b[0m\nPlotting labels to runs/train/exp/labels.jpg... \n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/exp\u001b[0m\nStarting training for 24 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n  0%|          | 0/114 00:09\nTraceback (most recent call last):\n  File \"/kaggle/working/yolov9/train.py\", line 634, in <module>\n    main(opt)\n  File \"/kaggle/working/yolov9/train.py\", line 528, in main\n    train(opt.hyp, opt, device, callbacks)\n  File \"/kaggle/working/yolov9/train.py\", line 303, in train\n    pred = model(imgs)  # forward\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 110, in parallel_apply\n    output.reraise()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_utils.py\", line 694, in reraise\n    raise exception\ntorch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov9/models/yolo.py\", line 633, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File \"/kaggle/working/yolov9/models/yolo.py\", line 533, in _forward_once\n    x = m(x)  # run\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov9/models/common.py\", line 80, in forward\n    x1 = self.cv1(x1)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov9/models/common.py\", line 54, in forward\n    return self.act(self.bn(self.conv(x)))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 85.06 MiB is free. Process 7437 has 14.66 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 244.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\nTraceback (most recent call last):\n  File \"/kaggle/working/yolov9/train.py\", line 634, in <module>\n    main(opt)\n  File \"/kaggle/working/yolov9/train.py\", line 528, in main\n    train(opt.hyp, opt, device, callbacks)\n  File \"/kaggle/working/yolov9/train.py\", line 303, in train\n    pred = model(imgs)  # forward\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 110, in parallel_apply\n    output.reraise()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_utils.py\", line 694, in reraise\n    raise exception\ntorch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov9/models/yolo.py\", line 633, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File \"/kaggle/working/yolov9/models/yolo.py\", line 533, in _forward_once\n    x = m(x)  # run\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov9/models/common.py\", line 80, in forward\n    x1 = self.cv1(x1)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov9/models/common.py\", line 54, in forward\n    return self.act(self.bn(self.conv(x)))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 85.06 MiB is free. Process 7437 has 14.66 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 244.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls {HOME}/yolov9/runs/train/exp/","metadata":{"id":"Tu0YItOagAH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(filename=f\"{HOME}/yolov9/runs/train/exp/results.png\", width=1000)","metadata":{"id":"3-ymovJWgAH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(filename=f\"{HOME}/yolov9/runs/train/exp/confusion_matrix.png\", width=1000)","metadata":{"id":"yjEIzzQFgAH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(filename=f\"{HOME}/yolov9/runs/train/exp/val_batch0_pred.jpg\", width=1000)","metadata":{"id":"eao73RK3gAH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}/yolov9\n\n!python val.py \\\n--img 640 --batch 32 --conf 0.001 --iou 0.7 --device 0 \\\n--data {dataset.location}/data.yaml \\\n--weights {HOME}/yolov9/runs/train/exp/weights/best.pt","metadata":{"id":"5PUdfIrqgAH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py \\\n--img 1280 --conf 0.1 --device 0 \\\n--weights {HOME}/yolov9/runs/train/exp/weights/best.pt \\\n--source {dataset.location}/test/images","metadata":{"id":"j3eeVeI8gAH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\n\nfrom IPython.display import Image, display\n\nfor image_path in glob.glob(f'{HOME}/yolov9/runs/detect/exp3/*.jpg')[:2]:\n      display(Image(filename=image_path, width=600))","metadata":{"id":"G84n9dPKgAH-"},"execution_count":null,"outputs":[]}]}